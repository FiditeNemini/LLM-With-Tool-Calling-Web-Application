{
  "id": "3082129b-a18a-4062-9565-c6587ff2372e",
  "last_updated": "2025-01-13T17:12:06.226846",
  "messages": [
    {
      "role": "user",
      "content": "show me a video tutorial for LM studio"
    },
    {
      "role": "assistant",
      "tool_calls": [
        {
          "id": "996354706",
          "type": "function",
          "function": {
            "name": "video",
            "arguments": "{\"query\": \"LM studio tutorial\", \"number_of_videos\": 1}"
          }
        }
      ]
    },
    {
      "role": "tool",
      "content": "[{'title': 'LM Studio Tutorial: Run Large Language Models (LLM) on Your Laptop', 'url': 'https://www.youtube.com/watch?v=ygUEbCpOOLg'}]",
      "tool_call_id": "996354706"
    },
    {
      "role": "assistant",
      "content": "Here is a video tutorial for LM studio that you can watch:\n\n[LM Studio Tutorial: Run Large Language Models (LLM) on Your Laptop](https://www.youtube.com/watch?v=ygUEbCpOOLg)\n\nYou can click on the title to directly access the video. Enjoy learning!"
    },
    {
      "role": "user",
      "content": "what LLM he used in the video?"
    },
    {
      "role": "assistant",
      "content": "Let's check the video description or details to find out which Large Language Model (LLM) is used in the tutorial.\n"
    },
    {
      "role": "assistant",
      "tool_calls": [
        {
          "id": "993013695",
          "type": "function",
          "function": {
            "name": "yt_url",
            "arguments": "{\"url\": \"https://www.youtube.com/watch?v=ygUEbCpOOLg\"}"
          }
        }
      ]
    },
    {
      "role": "tool",
      "content": "{'title': 'LM Studio Tutorial: Run Large Language Models (LLM) on Your Laptop', 'content': \"In this video, I'll show you how to run large language models (LLMs) right on your laptop using LM Studio! LM Studio uses GPU offloading to break down complex AI models, allowing you to run them smoothly on almost any laptop. With LM Studio accelerated by NVIDIA RTX GPUs, you unlock faster performance and better handling of larger models, giving you power and speed for advanced workflows. Whether you're generating text, summarizing documents, or asking questions, I'll guide you through the installation process, how to load and use models like Llama and Gemma, and even how to upload files for analysis\u2014all while keeping your data secure on your PC. Perfect for those who want to explore AI without relying on cloud services!\\n\\nHost: Kevin Stratvert\\n\\n\ud83d\udcda RESOURCES\\n- Learn more and download LM Studio here: https://nvda.ws/3YhC91P\\n\\n\u231a TIMESTAMPS\\n0:00 - Introduce LM Studio\\n0:41 - Download and Install LM Studio\\n1:41 - Download and Load Your First LLM (Llama 3.2 1B)\\n2:48 - Interact with AI in LM Studio (Chocolate Chip Cookie Example)\\n3:18 - Upload Documents and Interact with Them\\n3:50 - Explore Other LLMs in LM Studio (Mistral, Gemma)\\n5:36 - Wrap Up\\n \\n\ud83d\udce9 NEWSLETTER\\n- Get the latest high-quality tutorial and tips and tricks videos emailed to your inbox each week: https://kevinstratvert.com/newsletter/\\n\\n\ud83d\udd3d CONNECT WITH ME\\n- Official website: http://www.kevinstratvert.com\\n- LinkedIn: https://www.linkedin.com/in/kevinstratvert/\\n- Discord: https://bit.ly/KevinStratvertDiscord\\n- Twitter: https://twitter.com/kevstrat\\n- Facebook: https://www.facebook.com/Kevin-Stratvert-101912218227818\\n- TikTok: https://www.tiktok.com/@kevinstratvert\\n- Instagram: https://www.instagram.com/kevinstratvert/\\n\\n\ud83c\udf81 TOOLS AND DISCOUNTS\\n\u2705 \ud83c\udf99\ufe0f Voicemod AI Voice Changer | 5% off | https://link.xsolla.com/KZBi89AY\\n\u2705 \ud83d\udcfa Descript AI Video Editor | https://get.descript.com/sf22jb63w2tx\\n\u2705 \ud83d\udcb5 QuickBooks Online: https://bit.ly/intuitquickbooksonline\\n\u2705 \ud83c\udf10 Squarespace Websites | https://squarespace.syuh.net/XYaqYM\\n\u2705 \ud83d\udd0d Grammarly | https://grammarly.go2cloud.org/SH3nL\\n\u2705 \ud83d\udcf9 CapCut Video Editor | https://bit.ly/installcapcut\\n\u2705 \ud83d\udecd\ufe0f Shopify | https://shopify.pxf.io/XY9rPa\\n\u2705 \ud83d\udccb Notion | https://affiliate.notion.so/rffva4tr71ax\\n\u2705 \ud83e\udd16 ElevenLabs Text-to-Speech | https://try.elevenlabs.io/taqepq60mptr\\n\\n\ud83c\udf92 MY COURSES\\n- Go from Excel novice to data analysis ninja in just 2 hours: https://kevinstratvert.thinkific.com/\\n\\n\ud83d\ude4f REQUEST VIDEOS\\nhttps://forms.gle/BDrTNUoxheEoMLGt5\\n\\n\ud83d\udd14 SUBSCRIBE ON YOUTUBE\\nhttps://www.youtube.com/user/kevlers?sub_confirmation=1\\n\\n\ud83d\ude4c SUPPORT THE CHANNEL\\n- Hit the THANKS button in any video!\\n- Amazon affiliate link: https://amzn.to/3kCP2yz\\n\\n\u2696 DISCLOSURE\\nSome links are affiliate links. Purchasing through these links gives me a small commission to support videos on this channel. The price to you is the same.\\n\\n#stratvert #lmstudio\", 'transcription': 'Today, we\\'re going to learn how you can run large\\xa0\\nlanguage models or LLMs right on your laptop using\\xa0\\xa0 LM Studio. Typically, to be able to run a large\\xa0\\nand complex LLM, you would need at least 16\\xa0\\xa0 gigabytes of VRAM like you\\'d get with the GeForce\\xa0\\nRTX 4080 Super Desktop GPU or a GeForce RTX 4090\\xa0\\xa0 which helps break the model\\'s data into smaller\\xa0\\npieces, so your laptop, no matter how powerful,\\xa0\\xa0 can run it smoothly. Let\\'s check out how to get\\xa0\\nLM Studio. First off, navigate to the following\\xa0\\xa0 website. Here, you can learn about how LM Studio\\xa0\\nis able to run powerful AI models on your PC.\\xa0\\xa0 Towards the bottom of the page, click on this link\\xa0\\nthat says Download LM Studio. You can download and\\xa0\\xa0 install LM Studio on Mac, Windows, and also Linux.\\xa0\\nI recommend having at least 16 gigabytes of RAM\\xa0\\xa0 or memory on your PC to be able to install\\xa0\\nLM Studio. To check how much RAM you have,\\xa0\\xa0 on a Windows PC, press Ctrl Shift Escape. This\\xa0\\nopens up Task Manager. Over on the left-hand side,\\xa0\\xa0 let\\'s click on the performance icon. And the\\xa0\\nsecond item here is memory. You need to make sure\\xa0\\xa0 that you have at least 16 gigabytes of RAM. If\\xa0\\nyou have that, you should be able to install and\\xa0\\xa0 run LM Studio without any issues. Once you confirm\\xa0\\nthat, let\\'s go back to the website and right here,\\xa0\\xa0 click on Download LM Studio for Windows and then\\xa0\\nrun through the install process. Once you launch\\xa0\\xa0 LM Studio, they\\'ll recommend starting by getting\\xa0\\nyour first LLM. Let\\'s click on this button,\\xa0\\xa0 and here they recommend Llama 3.2 1B made by Meta.\\xa0\\nThis is a good general purpose LLM designed for\\xa0\\xa0 a wide range of tasks like text generation,\\xa0\\nsummarization, answering questions, and more.\\xa0\\xa0 Right here, let\\'s click on Download. Once it\\'s all\\xa0\\ndone downloading, let\\'s click on the button that\\xa0\\xa0 says Start New Chat. This drops us into a chat\\xa0\\nwindow where we can interact with the AI. But\\xa0\\xa0 before we can do that, we have to load a model.\\xa0\\nRight up on top, let\\'s click on this button, and\\xa0\\xa0 here I see the model that we just downloaded. I\\'ll\\xa0\\nclick on this one, and that opens up a variety of\\xa0\\xa0 different settings that we can configure. One item\\xa0\\nto call out, here we have the option to offload\\xa0\\xa0 some of the processing to the GPU, so this will\\xa0\\nresult in improved performance. And here I have\\xa0\\xa0 it moved all the way over to 16. If you\\'re\\xa0\\nunsure about what some of these settings do,\\xa0\\xa0 you could hover over it and you\\'ll see a tool tip\\xa0\\nthat gives you more information about what that\\xa0\\xa0 setting is. For now, all these settings and all\\xa0\\nthe defaults look good, so in the bottom right,\\xa0\\xa0 I\\'ll click on Load Model. Let\\'s now test it out.\\xa0\\nDown below, I can type in my prompt. I\\'ll say,\\xa0\\xa0 \"Give me the recipe for a chocolate chip cookie,\"\\xa0\\nand then let\\'s click on Send. Right up above,\\xa0\\xa0 I can see the output. Right here, I have all\\xa0\\nthe ingredients, we have the instructions, and\\xa0\\xa0 down at the bottom, we also have some additional\\xa0\\ntips. Overall, not bad. What I love about using\\xa0\\xa0 LM Studio is that this is all running on your PC.\\xa0\\nAll your data, all your prompts stay on your PC.\\xa0\\xa0 You don\\'t need internet and you don\\'t have to pay\\xa0\\nfor access to an AI service. Along with asking\\xa0\\xa0 text prompts, you can also upload documents and\\xa0\\nthen have conversations about those documents.\\xa0\\xa0 Over here, let\\'s click on the paperclip icon and I\\xa0\\nget a few other tips. Let\\'s click on Upload File.\\xa0\\xa0 I\\'ll navigate to where I have my file. Here, I\\xa0\\nhave a file about a brainstorming session and\\xa0\\xa0 then I\\'ll click on Open. In the text field, I can\\xa0\\nnow type in my prompt. Let me ask the question,\\xa0\\xa0 \"When is our next brainstorming session?\" I\\xa0\\nknow it\\'s somewhere in this document, but I\\xa0\\xa0 don\\'t want to open it up. Let\\'s send that through.\\xa0\\nThat was fast. It looks like it\\'s on May 14th,\\xa0\\xa0 2024. We\\'ve been using the Llama model, but you\\xa0\\ncan also install and use other LLMs. Over on the\\xa0\\xa0 left-hand side, let\\'s click on this folder icon\\xa0\\nand here you can see all the different models that\\xa0\\xa0 you have installed. Here, I just have one model\\xa0\\ncurrently, and in this column, we can see how\\xa0\\xa0 much disk space this model consumes. To install\\xa0\\nadditional LLMs, over on the left-hand side,\\xa0\\xa0 let\\'s click on the Discover icon. On this page,\\xa0\\nyou\\'ll see many different LLMs. At the top,\\xa0\\xa0 we see a few different variations of Llama. Here\\'s\\xa0\\nthe one that we installed and this is one of the\\xa0\\xa0 smaller models. The benefit, and you probably\\xa0\\nnoticed this when we typed in our prompt, is that\\xa0\\xa0 it\\'s really fast. Right down below, we also have a\\xa0\\nlarger version of that model. With a larger model,\\xa0\\xa0 you tend to get better quality results, but\\xa0\\nit also takes longer to process. In this list,\\xa0\\xa0 we also have the Mistral model, and this is one\\xa0\\nof the most popular open source models. There\\'s\\xa0\\xa0 also Gemma, and this one is made by Google. Up on\\xa0\\ntop, you can even search for models from Hugging\\xa0\\xa0 Face. If you\\'ve never heard of Hugging Face, it\\'s\\xa0\\na repository of a variety of different machine\\xa0\\xa0 learning models. To install one of these models,\\xa0\\nright here, I\\'ll select Gemma, and in the bottom\\xa0\\xa0 right, I\\'ll click on Download. Once it\\'s all done\\xa0\\ndownloading, right down here, we can click on\\xa0\\xa0 Load Model, and right up above, we can see that\\xa0\\nit\\'s currently loading this model. I\\'ll close\\xa0\\xa0 this download window. If you\\'d like to switch\\xa0\\nbetween the different models, simply click on this\\xa0\\xa0 drop-down, and then you can choose the model that\\xa0\\nyou would like to use. The benefit of installing\\xa0\\xa0 multiple LLMs is that it gives you flexibility to\\xa0\\nchoose the best model for different tasks. Some\\xa0\\xa0 might be better at technical help or maybe math,\\xa0\\nwhile others might be better at creative writing.\\xa0\\xa0 This way, you can compare them and then choose\\xa0\\nthe one that works the best for you. All right,\\xa0\\xa0 hopefully you\\'re now able to run LLMs directly on\\xa0\\nyour laptop. If you have any questions, feel free\\xa0\\xa0 to ask them down below in the comments. Please\\xa0\\nconsider subscribing, and I\\'ll see you next time.'}",
      "tool_call_id": "993013695"
    },
    {
      "role": "assistant",
      "content": "In the video tutorial, the Large Language Model (LLM) used is **Llama 3.2 1B** made by Meta. The host mentions that this model is a good general-purpose LLM designed for tasks like text generation, summarization, and answering questions.\n\nAdditionally, the video also demonstrates using other models such as Mistral and Gemma."
    }
  ],
  "name": "LM Studio Tutorial Analysis"
}